{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics und Künstliche Intelligenz\n",
    "Wintersemester 2023/2024\n",
    "\n",
    "Prof. Dr. Jürgen Bock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungen zu den Grundlagen künstlicher Neuronaler Netze in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook bietet Übungsaufgaben zum grundlegenden Umgang mit künstlichen Neuronalen Netzen in *PyTorch*. Die einzelnen Aufgaben sind in Markdown-Zellen beschrieben. Fügen Sie Ihre Lösung in die jeweils nachfolgende Code-Zelle ein und fügen Sie bei Bedarf gerne weitere Code-Zellen hinzu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lernziele\n",
    "* Sie sind in der Lage einfache künstliche Neuronen zu implementieren und die Einflüsse der einzelnen Komponenten zu untersuchen.\n",
    "* Sie sind in der Lage strukturierte Datensätze zur Verwendung in *PyTorch* vorzubereiten und einfache mehrschichtige künstliche neuronale Netze zu strukturieren.\n",
    "* Sie sind in der Lage eigene neuronale Netzstrukturen in einen generischen Lernalgorithmus einzuordnen und mit verschiedenen Datensätzen zu trainieren.\n",
    "* Sie sind in der Lage den Einfluss verschiedener Hyperparameter auf den Lernprozess und Qualität des gelernten Modells bei künstlichen neuronalen Netzen zu untersuchen und zu diskutieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einfache Neuronen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie die Bool'sche Funktion *NAND*.\n",
    "\n",
    "Die Wahrheitstafel für NAND ist wie folgt:\n",
    "\n",
    "| NAND | 0 | 1 |\n",
    "|-----|---|---| \n",
    "| **0**   | 1 | 1 |\n",
    "| **1**   | 1 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warum ist diese Funktion durch ein einzelnes Neuron berechenbar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Antwort:* Sie ist linear separierbar, d.h. die Samples der einzelnen Klassen sind durch eine lineare Funktion trennbar. (Hier eine Gerade.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überlegen Sie sich wie dieses eine Neuron konfiguriert sein müsste. (Eingänge, Gewichte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Antwort:* Die beiden Eingänge werden negativ gewichtet, der Bias positiv. Dabei ist darauf zu achten, dass das Einfluss des Bias die Eingangssumme gerade dann größer als 0 werden lässt, wenn höchstens einer der beiden Eingänge 1 ist, also das Eingangsgewicht zur Geltung kommt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie die Berechnung in Python und testen Sie Ihre Lösung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 1\n",
    "x2 = 1\n",
    "\n",
    "w03 = 1.5\n",
    "w13 = -1\n",
    "w23 = -1\n",
    "\n",
    "y = threshold(w03 + x1*w13 + x2*w23)\n",
    "print('{} NAND {} -> {}'.format(x1, x2, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mehrschichtige neuronale Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie den folgenden (synthetischen) Datensatz mit zwei Merkmalen und zwei Klassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.make_circles(\n",
    "    n_samples = 10000,\n",
    "    noise = 0.1,\n",
    "    factor = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machen Sie sich mit dem Datensatz vertraut indem Sie einen Scatter-Plot erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = data\n",
    "plt.scatter(X[:,0], X[:,1], c=t, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definieren Sie ein mehrschichtiges neuronales Netz mittels *PyTorch*, und implementieren Sie eine Trainingsroutine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(t))\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP( nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super( MLP, self ).__init__()\n",
    "        self.fc1 = nn.Linear( 2, 3 )\n",
    "        self.fc3 = nn.Linear( 3, 1 )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        x = torch.sigmoid( self.fc1( x ) )\n",
    "        x = torch.sigmoid( self.fc3( x ) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from statistics import mean\n",
    "loss_history = []\n",
    "loss_ep = []\n",
    "plt.figure(figsize = (12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader :\n",
    "        optimizer.zero_grad()\n",
    "        input, target = batch\n",
    "        output = model(input.float())\n",
    "        loss = loss_fn(output, torch.unsqueeze(target.float(), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep.append(loss.item())\n",
    "    \n",
    "    ## Zu Visualisierungszwecken:\n",
    "    loss_history.append(mean(loss_ep))\n",
    "    loss_ep = []\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(loss_history)\n",
    "    #dataview.plot_decision_boundary2d(model, X, t, showData=False)\n",
    "    display.display(plt.gcf())\n",
    "    display.display(print(\"Epoch {:2}, loss: {}\".format(epoch, loss_history[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen Sie sicher, dass das Modul ``dataview`` im aktuellen Verzeichnis liegt (oder in ``sys.path``). Verwenden Sie die Funktion ``dataview.plot_decision_boundary2d(model, X, y)`` um die *decision boundary* darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataview.plot_decision_boundary2d(model, X, t, showData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentieren Sie mit den sogenannten *Hyperparametern*: Verändern Sie Anzahl und Breite der Layer, verändern Sie Anzahl der Epochen und die *batch size*. Konsultieren Sie die *PyTorch* API Dokumentation und experimentieren Sie mit verschiedenen Aktivierungsfunktionen und Optimierern.\n",
    "\n",
    "**Beachten Sie:** Nach Veränderung des Modells muss die Objektinstanz des Modells neu instanziiert werden (z.B. ``model = Net()``). Außerdem muss der Optimierer und etwaige Hilfsvariablen, wie z.B. eine ``loss_history`` o.ä., neu initialisiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Erkenntnisse haben Sie erlangt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Antwort:*\n",
    "\n",
    "- Es genügt ein Netzwerk mit einer kleinen *hidden layer* um dieses Klassifizierungsproblem zu lösen. 3 Neuronen in der *hidden layer* funktionieren. Je mehr Neuronen in der *hidden layer* umso genauer wird der Kreis approximiert.\n",
    "- Die *sigmoid* Funktion als Aktivierungsfunktion funktioniert.\n",
    "- Die Robustheit und Geschwindigkeit der Konvergenz hängt vom Optimierer ab. *Adam* funktioniert deutlich besser als *SGD*.\n",
    "- Die Learning Rate ist für beide Optimierungsalgorithmen unterschiedlich effektiv. Dieses Klassifizierungsproblem ist relativ robust gegenüber größeren Learaning Rates. Offensichtlich gibt es keine großen Gefahren durch lokale Minima im Gewichtsraum.\n",
    "- Eine kleine *batch size* (im Extremfall 1) führt zu einer deutlichen Verlangsamung der Iteration über die Epochen. Dafür ist bereits nach einer Epoche eine sehr gute Näherung gefunden. Eine große *batch size* führt zu einer schnellen Iteration über die Epochen, die Konvergenz verläuft langsamer. Damit wäre das Modell robuster gegenüber Overfitting (\"Auswendiglernen des Trainingsdatensatzes\"). Dieser Effekt ist hier aber nicht zu beobachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reale Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwenden Sie ``scikit-learn`` um den *Breast Cancer Wisconsin* Datensatz zu laden. Siehe: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Anzahl features:', len(data.feature_names))\n",
    "print(data.feature_names)\n",
    "print('Anzahl Klassen:', len(data.target_names))\n",
    "print(data.target_names)\n",
    "print('Anzahl Samples:', len(data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machen Sie sich mit der Funktion ``train_test_split`` aus dem Modul ``sklearn.model_selection`` vertraut. Verwenden Sie diese Funktion um den Datensatz in eine Trainings- und eine Testmenge aufzuteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definieren Sie ein neuronales Netz und verwenden Sie den Trainingsdatensatz um es zu trainieren. Beachten Sie bei der neuronalen Netzstruktur die Größe des Eingabe- und Ausgabevektors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset_train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__( self ):\n",
    "        super( MLP, self ).__init__()\n",
    "        self.fc1 = nn.Linear( 30, 50 )\n",
    "        self.fc2 = nn.Linear( 50, 20 )\n",
    "        self.fc3 = nn.Linear( 20, 5 )\n",
    "        self.fc4 = nn.Linear( 5, 1 )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        x = F.relu( self.fc1( x ) )\n",
    "        x = F.relu( self.fc2( x ) )\n",
    "        x = F.relu( self.fc3( x ) )\n",
    "        x = torch.sigmoid( self.fc4( x ) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "loss_history = []\n",
    "loss_ep = []\n",
    "plt.figure(figsize = (12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader :\n",
    "        optimizer.zero_grad()\n",
    "        input, target = batch\n",
    "        output = model(input.float())\n",
    "        loss = loss_fn(output, torch.unsqueeze(target.float(), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep.append(loss.item())\n",
    "    \n",
    "    ## Zu Visualisierungszwecken:\n",
    "    loss_history.append(mean(loss_ep))\n",
    "    plt.plot(loss_history)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    display.display(print(\"Epoch {:2}, loss: {}\".format(epoch, loss_history[-1])))\n",
    "    loss_ep = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwenden Sie ``scikit-learn`` um einen *classification report* zu erstellen, anhand dessen Sie ihr Modell bewerten können.\n",
    "\n",
    "Berechnen Sie dazu zuerst den Ausgangsvektor ihres neuronalen Netzes für die Eingabevektoren des Testdatensatzes. \n",
    "\n",
    "**Hinweis:** ``torch.from_numpy`` erstellt einen Tensor aus einem *NumPy*-Array, in dem der Testdatensatz vorliegt. Zudem müssen Sie den Eingabevektor in einen ``FloatTensor`` konvertieren.\n",
    "\n",
    "Für den *classification report* müssen Sie außerdem die Fließkommazahlen des Ausgangsvektors (resultierend aus der ``sigmoid`` Aktivierungsfunktion) in einen ganzzahlige Werte umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model(torch.from_numpy(X_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(t_test, torch.round(y_test).int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(t_test, torch.round(y_test).int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
