{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Business Analytics und Künstliche Intelligenz\n",
    "\n",
    "Prof. Dr. Jürgen Bock & Maximilian-Peter Radtke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein erstes Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Einheit soll es darum gehen ein erstes Modell zu erstellen um eine Regression durchzuführen. Hierfür werden wir das Python Package `statsmodels` verweden. Eine lineare Regression kann auch über `scikit-learn` angewandt werden, aber hier werden nicht alle statistischen Kennzahlen angegeben, welche sehr wichtig für die Interpretation der Ergebnisse sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Statsmodels](\"https://www.statsmodels.org/stable/index.html\") ist ein Pythonmodul, welches Klassen und Funktionen für die Schätzung verschiedener statistsicher Modelle und Tests bereitstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls Sie das erste Mal mit statsmodels arbeiten, müssen Sie das statsmodels Paket zunächst [installieren](\"https://www.statsmodels.org/stable/install.html\"). Dies können Sie mit dem Befehl `conda install statsmodels` über die Konsole machen (der Ort von dem Sie auch Jupyter Notebook starten). Alternativ können Sie auch direkt über Jupyter das neue Paket installieren. Dazu müssen Sie nur die folgende Zelle ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation eines Conda Pakets im aktuellen Kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können Sie das Paket importieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wollen wir uns denn Datensatz zu den Werbeausgaben aus der Vorlesung genauer ansehen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenverständnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv('Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(ad, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits in der Vorlesung besprochen, sehen wir einen starken linearen Zusammenhang zwischen TV-Werbesausgaben und Sales. Diesen Zusammenhang werden wir nutzen, um ein erstes lineares Modell zu erzeugen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Statsmodels hierfür zu nutzen, müssen wir unseren Daten zunächst eine Spalte mit dem Wert 1 hinzufügen, welche als $\\beta_0$ genutzt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes initialisieren wir das Modell für die lineare Regression. Hierfür nutzen wir `OLS`, was für **O**rdinary **L**east **S**quares - Methode der kleinsten Quadrate steht. Dafür übergeben wir der Methode die Zielvariable und den Prädiktor TV, inklusive unserem Dummy Wert für $\\beta_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modTV = sm.OLS(ad.sales, ad.loc[:,['TV', 'intercept']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modTV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Parameter $\\hat{\\beta}_0$ und $\\hat{\\beta}_1$ zu schätzen rufen wir von unserem initialisierten Modell die Methode `fit` auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTV = modTV.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Parameter sind nun geschätzt und wir können uns die Zusammenfassung der Resultate anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resTV.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes können wir unser Modell nutzen um Vorhersagen zu treffen. Hierfür nutzen wir die Methode `predict` und Plotten sie zusammen mit den bekannten Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ad.TV, ad.sales, s=10)\n",
    "plt.plot(ad.TV, resTV.predict(ad.loc[:,['TV', 'intercept']]), c='red')\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt schauen wir uns das Modell mit allen Variablen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modAll = sm.OLS(ad.sales, ad.loc[:,['TV', 'radio', 'newspaper', 'intercept']])\n",
    "resAll = modAll.fit()\n",
    "resAll.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir Interaktionen zwischen Variablen modellieren möchten, müssen wir diese in unserem Ausgangsdatensatz hinterlegen. Hierfür erzeugen wir neue Spalten, welche der Interaktion entsprechen. Der multiplikative Zusammenhang zwischen TV und radio wird wie folgt dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad['TVXradio'] = ad.TV * ad.radio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese neue Spalte können wir direkt in ein neues Modell aufnehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modInter = sm.OLS(ad.sales, ad.loc[:,['TV', 'radio', 'TVXradio', 'intercept']])\n",
    "resInter = modInter.fit()\n",
    "resInter.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Datensatz können wir uns auch nochmals den Bias Variance Tradeoff ansehen. Dazu starten wir zunächst mit dem simplen Modell, mit dem der Umsatz nur durch die TV-Ausgaben vorhergesagt wird. Danach machen wir das Modell stetig flexibler (erhöhen sozusagen die Varianz) indem wir das Polynom um eine Ordnung erhöhen.\n",
    "\n",
    "Entsprechend haben wir die Modelle:\n",
    "\n",
    "TV_1: $y = \\beta_0 + \\beta_1 x$ \\\n",
    "TV_2: $y = \\beta_0 + \\beta_1 x + \\beta_2 x^2$ \\\n",
    "TV_3: $y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3$ \\\n",
    "...\n",
    "\n",
    "Wir evaluieren wie gut die verschiedenen Modelle sind, indem wir $R^2$ auf Daten berechnen, die vorher nicht für das Training genutzt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def r_squared(y_true, y_pred):\n",
    "    # Calculate the mean of the actual values\n",
    "    y_mean = np.mean(y_true)\n",
    "    # Calculate the total sum of squares (TSS)\n",
    "    tss = np.sum((y_true - y_mean) ** 2)\n",
    "    # Calculate the residual sum of squares (RSS)\n",
    "    rss = np.sum((y_true - y_pred) ** 2)\n",
    "    # Calculate R-squared\n",
    "    return 1 - (rss / tss)   \n",
    "\n",
    "# Loop through specific fraction of data\n",
    "for n_frac in [0.9, 0.5, 0.1]:\n",
    "    # Only use part of the data for training\n",
    "    sampled = ad.sample(frac=n_frac, random_state=12)\n",
    "    # Use the rest for testing\n",
    "    not_sampled = ad.drop(sampled.index)\n",
    "    \n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.scatter(not_sampled.TV, not_sampled.sales, color='grey', alpha=0.5, label='Train data')\n",
    "    ax.scatter(sampled.TV, sampled.sales, color='blue', alpha=0.5, label='Test data')\n",
    "    print(f'{int(n_frac*ad.shape[0])} of {ad.shape[0]} datapoints used for training')\n",
    "\n",
    "    # Initialize model columns with \"intercept\" column\n",
    "    model_columns = ['intercept']\n",
    "\n",
    "    # Loop through polynomials of degree 1 to 9\n",
    "    for i in range(1, 10):\n",
    "        # Name of model\n",
    "        col_name = f'TV_{i}'\n",
    "        model_columns.append(col_name)\n",
    "        # Add ith polynomial\n",
    "        sampled[col_name] = sampled.TV ** i\n",
    "        not_sampled[col_name] = not_sampled.TV ** i\n",
    "        # Sort dataframe for plotting\n",
    "        sampled = sampled.sort_values(by='TV', ascending=True)\n",
    "        not_sampled = not_sampled.sort_values(by='TV', ascending=True)\n",
    "        # Create model\n",
    "        tmp_model = sm.OLS(sampled.sales, sampled.loc[:, model_columns])\n",
    "        tmp_res = tmp_model.fit()\n",
    "        # Output results\n",
    "        # Predictions\n",
    "        y_pred_test = tmp_res.predict(not_sampled.loc[:, model_columns])\n",
    "        y_true_test = not_sampled.sales\n",
    "        y_pred_train = tmp_res.predict(sampled.loc[:, model_columns])\n",
    "        y_true_train = sampled.sales\n",
    "        ax.plot(not_sampled.TV, y_pred_test, label=i)\n",
    "        ax.set_xlabel('TV')\n",
    "        ax.set_ylabel('Sales')\n",
    "        r2_train = r_squared(y_true_train, y_pred_train)\n",
    "        r2_test = r_squared(y_true_test, y_pred_test)\n",
    "        print(f\"{col_name} R2 Train: {r2_train:.3f} | R2 Test: {r2_test:.3f}\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiter machen wir mit dem Auto Datensatz von letzter Übung. Wir fügen auch hier direkt eine Spalte für $\\beta_0$ hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Auto_clean.csv')\n",
    "auto['intercept'] = 1\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit diesem Datensatz weiter arbeiten können, müssen wir Dummyvariablen für die qualitative Variable origin erstellen. Pandas stellt hierfür die Funktion `get_dummies` bereit, welche uns die händische Arbeit abnimmt. Mittels dem Parameter `drop_first` stellen wir ein, dass eine Variable weniger als die Anzahl der Ausprägungen hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyVar = pd.get_dummies(auto.origin, prefix='origin', drop_first=True, dtype=int)\n",
    "dummyVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von `concat` können wir die neuen Spalten dem alten Datensatz hinzufügen. Um sicherzugehen, dass die neuen Werte auch wirklich als Spalten (und nicht als Zeilen) hinzugefügt werden, übergeben wir den Parameter `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDum = pd.concat([auto, dummyVar], axis=1)\n",
    "autoDum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun bauen wir ein Modell nur mit den Dummy Variablen mit dem Zielwert mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modAutoOrig = sm.OLS(autoDum.mpg, autoDum.loc[:,[\"origin_2\", \"origin_3\", \"intercept\"]])\n",
    "resAutoOrig = modAutoOrig.fit()\n",
    "resAutoOrig.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsaufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "\n",
    "Erstellen Sie eine einfach Regression mit Prädiktor **horsepower** und Zielwert **mpg** auf Basis des Auto-Datensatzes. Geben Sie sich die Zusammenfassung des Modells aus.\n",
    "* Was fällt Ihnen auf? Zum Beispiel:\n",
    "    * Gibt es einen Zusammenhang zwischen Prädiktor und Zielvariable?\n",
    "    * Wie stark ist der Zusamenhang zwischen Prädiktor und Zielvariable?\n",
    "    * Ist der Zusammenhang positiv oder negativ?\n",
    "    * Was ist der vorhergesagte Wert von mpg für horsepower = 95?\n",
    "* Plotten Sie die Regressionslinie und die zugrundeliegenden Daten in einem Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Auto_clean.csv')\n",
    "auto['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoMod = sm.OLS(auto.mpg, auto[['horsepower', 'intercept']])\n",
    "autoRes = autoMod.fit()\n",
    "autoRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoRes.predict([95,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(auto.horsepower, auto.mpg, s=10)\n",
    "plt.plot(auto.horsepower, autoRes.predict(auto[['horsepower', 'intercept']]), color='red')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "\n",
    "Benutzen Sie wieder den Auto-Datensatz und **mpg** als Zielvariable.\n",
    "* Erstellen Sie eine lineare Regression und nutzen Sie alle Variablen.\n",
    "    * Gibt es einen Zusammenhang zwischen den Prädiktoren und der Zielvariable?\n",
    "    * Welche Prädiktoren scheinen einen signifikanten Einfluss zu haben?\n",
    "    * Was suggeriert der Koeffizient für Jahr?\n",
    "* Schätzen Sie eine Regression mit Interaktionen (Multiplikation oder Division). Sind irgendwelche Interaktionen statistisch signifikant?\n",
    "* Nutzen Sie andere Transformationen für die Variabeln in der Regression, z.B. $X^2, \\log{(X)}, \\sqrt{X}$. Beschreiben Sie ihre Erkenntnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyVar = pd.get_dummies(auto.origin, prefix='origin', drop_first=True, dtype=int)\n",
    "autoDum = pd.concat([auto, dummyVar], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoAllMod = sm.OLS(autoDum.mpg, autoDum.drop(['mpg', 'name', 'origin'], axis=1))\n",
    "autoAllRes = autoAllMod.fit()\n",
    "autoAllRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoDum['CylinderXDisplacement'] = autoDum.cylinders * autoDum.displacement\n",
    "autoDum['DisplacementXWeight'] = autoDum.displacement * autoDum.weight\n",
    "autoInterMod = sm.OLS(\n",
    "    autoDum.mpg,\n",
    "    autoDum[['CylinderXDisplacement', 'DisplacementXWeight', 'cylinders', 'weight', 'displacement', 'intercept']]\n",
    ")\n",
    "autoInterRes = autoInterMod.fit()\n",
    "autoInterRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDum['horsepower2'] = auto.horsepower * auto.horsepower\n",
    "autoHP2Mod = sm.OLS(autoDum.mpg, autoDum[['horsepower', 'horsepower2', 'intercept']])\n",
    "autoHP2Res = autoHP2Mod.fit()\n",
    "autoHP2Res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(autoDum.horsepower, autoDum.mpg, s=10)\n",
    "plt.plot(\n",
    "    autoDum.sort_values(by='horsepower').horsepower,\n",
    "    autoHP2Res.predict(autoDum[['horsepower', 'horsepower2', 'intercept']].sort_values(by='horsepower')),\n",
    "    color='red'\n",
    ")\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d4e26e01b905ad5810f153cf76e8bab0e96b068c4b859f49c5190a2dd823eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
